{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yl-PKGEcT4Rm",
   "metadata": {
    "id": "yl-PKGEcT4Rm"
   },
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://site.wandb.ai/wp-content/uploads/2025/07/wb_by_cw_black.svg?w=591\" width=\"1200\" alt=\"Weights & Biases\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae8d5f",
   "metadata": {
    "id": "e6ae8d5f"
   },
   "source": [
    "# ü™ê Operation REBOOT: Mission Start\n",
    "\n",
    "Welcome, **Neural Architect**. The ship's AI core is down. Your job: fine-tune a foundational model with astronomical data to restore its deep space knowledge. This notebook will walk you through all the necessary steps and even help you test and evaluate your final model. \n",
    "\n",
    "**Your mission:**\n",
    "- Load and adjust the data \n",
    "- Configure training arguments\n",
    "- Launch training in High Performance Compute and monitor with **Weights & Biases (W&B) by CoreWeave**\n",
    "- Test and evaluate your fine-tuned model\n",
    "\n",
    "All systems go. Let's bring this vessel back online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z4hJWD_fQ_CA",
   "metadata": {
    "id": "Z4hJWD_fQ_CA"
   },
   "source": [
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90bdba8-9688-4294-9af2-c23adc084833",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb weave datasets transformers sentence-transformers peft boto3 bitsandbytes --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Lcd7lpzkRH5a",
   "metadata": {
    "id": "Lcd7lpzkRH5a"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e039a1-4194-4ae4-8338-ed31bd097d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.helpers import * #helper functions used throughout our notebook. Take a peek here while your training job runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022b8ad",
   "metadata": {
    "id": "e022b8ad"
   },
   "source": [
    "## üîå Connect Neural Telemetry (W&B Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2252cad",
   "metadata": {
    "id": "b2252cad"
   },
   "outputs": [],
   "source": [
    "WANDB_ENTITY =  \"fc25-london-aise-likeyandy\" #Go to https://wandb.ai/ to see it!\n",
    "WANDB_PROJECT_NAME = \"CoreWeave-Astros-FT-Workshop\" #Name it however you'd like!\n",
    "\n",
    "# What is a team? or a project? Learn more in our docs: https://docs.wandb.ai/platform/app/settings-page/teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c79fd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5c79fd6",
    "outputId": "bc53d709-9eb1-419a-cdda-9bac5d1ff6ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait to be prompted to authenticate your wandb account \n",
    "# You can find your API key in your browser here: https://wandb.ai/authorize\n",
    "# Paste an API key from your profile and hit enter:\n",
    "wandb.login(relogin=True, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67257b8",
   "metadata": {
    "id": "b67257b8"
   },
   "source": [
    "## üß™ Dataset Control Room\n",
    "In order to perform fine tuning of a base model, we need to adjust the source dataset and prepare the astronomical data for training. This is data engineering work that is paramount to enable a high quality fine tune that will allow our vessel to perform well in deep space!\n",
    "\n",
    "We do all this by leveraging [W&B Artifacts](https://docs.wandb.ai/models/artifacts) -- they are an extremely poweful way to keep track and share huge amounts of data. Check them out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8b93f",
   "metadata": {
    "id": "e3f8b93f"
   },
   "source": [
    "## üåé Initialize Experiment, Read Data, Split Data ‚òÑÔ∏è\n",
    "\n",
    "In this section, we:\n",
    "\n",
    "* Retrieve the Astros Dataset from [W&B Registry FC_FT_Workshop_Dataset collection](https://wandb.ai/orgs/fcLondon-workshop/registry/dataset?selectionPath=fclondon-workshop%2Fwandb-registry-dataset%2FFC_FT_Workshop_Dataset&view=versions) \n",
    "* Load the Astro Dataset containing universe-related Q&A data.\n",
    "* Create prompts from the question/answer pairs & load into a pandas dataframe\n",
    "\n",
    "\n",
    "<img src=\"https://static.vecteezy.com/system/resources/previews/049/735/941/non_2x/edge-rocket-engine-isolated-on-transparent-background-free-png.png\" width=\"300\" alt=\"Weights & Biases\" />\n",
    "\n",
    "‚úÖ All the heavy lifting is done here automatically ‚Äî no manual setup needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9239842",
   "metadata": {
    "id": "f9239842"
   },
   "source": [
    "#### Let's prepare our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4602a18a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "4602a18a",
    "outputId": "ec723b7f-2c25-4b41-a2b4-3eafc276fdae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/quest_notebooks/operation-reboot-aetherion-protocol/wandb/run-20251104_112413-Operation_Reboot_0324</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">Operation_Reboot_0324</a></strong> to <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Downloading dataset from Weights & Biases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset downloaded successfully!\n",
      "\n",
      "Loading training dataset...\n",
      "‚úÖ Successfully loaded dataset with no errors.\n",
      "‚úÖ Training dataset loaded with 1600 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Operation_Reboot_0324</strong> at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a><br> View project at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251104_112413-Operation_Reboot_0324/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Training examples: 1600\n",
      "\n",
      "Example prompt format:\n",
      "Question: What are 'Superluminous Supernovae' (SLSNe) and what distinguishes Type I SLSNe from normal Type Ia supernovae spectroscopically?\n",
      "Answer: Superluminous Supernovae (SLSNe) are much more luminous than normal Type Ia supernovae. Spectroscopically, Type I SLSNe are characterized by the absence of hydrogen and strong helium lines near peak light (like normal SNe Ia), but they show strong, broad metal lines, often including oxygen, magnesium, and calcium. Normal SNe Ia are defined by the presence of strong silicon absorption lines (Si II Œª6355) near peak light, which are often weak or absent in SLSNe I. The differences in spectra indicate different progenitor systems and explosion mechanisms: SNe Ia are thermonuclear disruptions of white dwarfs, while SLSNe I are thought to be core-collapse explosions of massive stars, often powered by magnetars or CSM interaction, despite their lack of hydrogen.\n"
     ]
    }
   ],
   "source": [
    "local_tz = pytz.timezone(\"US/Pacific\")\n",
    "timestamp = datetime.now(local_tz).strftime(\"%H%M\")\n",
    "\n",
    "# Step 1: Initialize W&B run and download dataset\n",
    "run = wandb.init(entity=WANDB_ENTITY,\n",
    "                 project=WANDB_PROJECT_NAME,\n",
    "                 id=f\"Operation_Reboot_{timestamp}\",\n",
    "                 resume=\"allow\")\n",
    "\n",
    "print(\"Step 1: Downloading dataset from Weights & Biases...\")\n",
    "# Download the dataset artifact\n",
    "artifact = run.use_artifact('fc-london-admins/astro-datasets/astro_llm_training_dataset:v0', type='dataset')\n",
    "dataset_dir = artifact.download()\n",
    "print(\"‚úÖ Dataset downloaded successfully!\")\n",
    "\n",
    "# Step 2: Load and prepare datasets\n",
    "df_train, training_dataset = load_and_prepare_dataset(dataset_dir, \"astro_dataset_train.jsonl\", \"training\") #look at the helper fuctions if you're interested in how we prepare the data\n",
    "run.finish()\n",
    "# Print dataset statistics\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Training examples: {len(df_train)}\")\n",
    "print(\"\\nExample prompt format:\")\n",
    "print(df_train['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2ea11-d96b-40d6-9448-30c6dc3c2223",
   "metadata": {},
   "source": [
    "### üß™ Task 2: Systems Check - W&B by CoreWeave Telemetry Sync üö© Checkpoint üö©\n",
    "\n",
    "You've reached your first checkpoint. Follow the link above (\"View run at\") to see your run in the W&B environment. Grab the URL of the run and submit it on the quest page to get points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045aafb",
   "metadata": {
    "id": "9045aafb"
   },
   "source": [
    "### üåå Dataset Loaded Successfully!\n",
    "\n",
    "<img src=\"https://www.freeiconspng.com/thumbs/checkmark-png/checkmark-png-5.png\" width=\"150\" alt=\"Weights & Biases\" />\n",
    "\n",
    "\n",
    "At this point, we've:\n",
    "* Retrieved the Astros Dataset artifact\n",
    "* Loaded it into a pandas DataFrame\n",
    "* Created prompt-style text for fine-tuning\n",
    "\n",
    "‚ú® Feel free to pause and explore the data before moving forward!\n",
    "\n",
    "Exploring the dataset can help you:\n",
    "\n",
    "* Understand the kinds of questions and answers the model will learn from\n",
    "* Check for any strange patterns, formatting issues, or interesting insights\n",
    "* Discover Easter Eggs\n",
    "\n",
    "üõ°Ô∏è We've added soft error handling while loading, so if you accidentally modify the dataset file, you'll be warned if any loading issues happen.\n",
    "\n",
    "üëâ Quick Tip: You don't need to modify the dataset to proceed, but if you want to explore, you can run things like:\n",
    "\n",
    "```\n",
    "print(df_train.sample(5))\n",
    "print(df_train['question'].apply(len).describe())\n",
    "print(df_train['answer'].apply(len).describe())\n",
    "```\n",
    "\n",
    "When you're ready, move on to loading the model and tokenizing the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7001ed2e",
   "metadata": {
    "id": "7001ed2e"
   },
   "source": [
    "## üß† Model Vault: Download & Configure the Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5caa9d0",
   "metadata": {
    "id": "e5caa9d0"
   },
   "source": [
    "## üöÄ Load Pretrained Model and Prepare Dataset for Fine-Tuning üå†\n",
    "In this section, we:\n",
    "\n",
    "* Retrieve the Model to Finetune.\n",
    "* Select a pretrained language model.\n",
    "* Split the dataset into training and validation sets.\n",
    "* Finally, load the model and tokenizers to prepare for finetuning in CoreWeave hardware (H200s üî•). \n",
    "\n",
    "‚úÖ All the setup for model loading, tokenization, and data splitting is handled for you ‚Äî no manual steps required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sblwkf4QihQZ",
   "metadata": {
    "id": "Sblwkf4QihQZ"
   },
   "source": [
    "### Select Model\n",
    "You will be prompted to select one of the following models\n",
    "\n",
    "*   Option 1: [falcon-rw-1b](https://huggingface.co/tiiuae/falcon-rw-1b)\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/apideck/image/upload/w_196,f_auto/v1686871384/marketplaces/ckhg56iu1mkpc0b66vj7fsj3o/listings/ii7e_5o4jBoK3pS8WMaWK_e7wsoh.webp\" width=\"200\" alt=\"Falcon\" />\n",
    "  \n",
    "*   Option 2: [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
    "\n",
    "<img src=\"https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-959993436-e1718640411389.jpg\" width=\"200\" alt=\"Falcon\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "WLBfMTo6h5sr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "WLBfMTo6h5sr",
    "outputId": "f49cfa52-bd51-4448-a8d6-1682dd608afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. Falcon RW 1B\n",
      "2. TinyLlama 1B\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a model (1-2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Selected: falcon-rw-1b\n",
      "\n",
      "‚¨áÔ∏è Downloading falcon-rw-1b (version v0) from Weights & Biases...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/quest_notebooks/operation-reboot-aetherion-protocol/wandb/run-20251104_112453-Operation_Reboot_0324</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">Operation_Reboot_0324</a></strong> to <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'falcon-rw-1b:v0', 2505.97MB. 43 files...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   43 of 43 files downloaded.  \n",
      "Done. 00:00:03.8 (659.0MB/s)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Operation_Reboot_0324</strong> at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a><br> View project at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251104_112453-Operation_Reboot_0324/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to: models/falcon-rw-1b_v0\n",
      "‚úÖ Model downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model_name, version = get_model_from_wandb(WANDB_ENTITY, WANDB_PROJECT_NAME, run_id=f\"Operation_Reboot_{timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26597b6b",
   "metadata": {
    "id": "26597b6b"
   },
   "source": [
    "\n",
    "\n",
    "Next, we'll make a few adjustments to ensure the model handles padding correctly,\n",
    "and then prepare our dataset for training by tokenizing the input prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff0e01",
   "metadata": {
    "id": "1dff0e01"
   },
   "source": [
    "## üîÑ Tokenize & Split: Format Data for Finetuning\n",
    "\n",
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2024/09/1QVXvydRMEWTWiUP42bYBAg.png\" width=\"400\" alt=\"Falcon\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6780204",
   "metadata": {
    "id": "c6780204"
   },
   "source": [
    "#### Load the datasets\n",
    "\n",
    "You can modify how our training data is passed to our training script to finetune the model. Make sure to analyze the data so you can select an appropriate **Sample Size** and  **Train/Test split** for the finetuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61faf47c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "6c83dd832f784383aa67a7bac1c81722",
      "02b048fcb50c451d89964ee93405cb93",
      "f7d0f2a7a7df4589b2ff1ea0562b8ae5",
      "ce5267e4265c49b08e066b4a5806e8cf",
      "c7a0ffa43bfd45bb82a110520ef065c6",
      "673061059cb64053896079a0de7d3458",
      "908c81b282f64785b4fa729646b00c98",
      "1173b7a21b3a4792bda7baa084fc5147",
      "b45860c163b142189b6eb2eaacdcc1f4",
      "9f3f09b8e4bc411880e0d389c2043a88",
      "da44f8d632714e7d89b2222686eafa5f",
      "c6c6c1949f1b4bbc9624647c4640dff9",
      "52c005c417a84f9aa9604239dd62197e",
      "f5926d20d7dc4bc5a784126f57867a59",
      "49be6b548baf43c5bcd1091e2bfd56f6",
      "ebfc99985a16470e8e49c9b788c18302",
      "3b119211b51a4c1e847bf9c8e2fbd28c",
      "ad5f99fdfdd942fab037f03f0f6c9107",
      "6fc3ad2df4a64a2aaba0d4567e3a9277",
      "ef60343739754ac7a5d61a82749f2f30",
      "e1ec82f4ca08434b85d3329bad4bf301",
      "ed9744b33f834485b653da828cf72026"
     ]
    },
    "id": "61faf47c",
    "outputId": "a6bde064-b7fb-4d79-c860-14a63d123c99"
   },
   "outputs": [],
   "source": [
    "sample_size = 100 # choose between 100 and 1600 samples to train. More samples can improve your model, but increase training time\n",
    "train_test_split = 0.1 # choose a float value between 0 and 1\n",
    "\n",
    "training_sample = training_dataset.shuffle(seed=42).select(range(sample_size)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b859f-98da-4084-8848-4954e9e4ab44",
   "metadata": {},
   "source": [
    "#### Load the model, tokenizers, and tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "w1DD36UhE0QJ",
   "metadata": {
    "editable": true,
    "id": "w1DD36UhE0QJ",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Loading model from: models/falcon-rw-1b_v0\n",
      "\n",
      "Step 1: Loading tokenizer...\n",
      "‚úÖ Tokenizer loaded successfully!\n",
      "\n",
      "Step 2: Configuring QLoRA...\n",
      "Loading model with 4-bit quantization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,582,912 || all params: 1,324,208,128 || trainable%: 0.9502\n",
      "‚úÖ Model loaded with QLoRA successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6c256c0434455c9983bda91b2f6923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e702623df62478e9d2cc9eb33e411f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization applied to Training & Evaluation Datasets successfully!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, model_name = load_model_and_tokenizer(model_name, version)\n",
    "train_dataset, eval_dataset = tokenized_train_test(training_dataset, train_test_split, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b86f5",
   "metadata": {
    "id": "e08b86f5"
   },
   "source": [
    "## ‚öôÔ∏è Training Command Center\n",
    "Set training arguments to guide your model's learning trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65c01f",
   "metadata": {
    "id": "5e65c01f"
   },
   "source": [
    "## üõ∞Ô∏è Training Arguments (Where You Fine-Tune Settings) üåô\n",
    "\n",
    "\n",
    "<img src=\"https://www.svgrepo.com/show/330922/weights-and-biases.svg\" width=\"200\" alt=\"Falcon\" />\n",
    "\n",
    "This is where you'll do most of your experimentation! üéØ\n",
    "\n",
    "The `TrainingArguments` object controls how your model is fine-tuned, including:\n",
    "\n",
    "* Batch size\n",
    "* Number of epochs\n",
    "* Learning rate\n",
    "* Warmup steps\n",
    "* Mixed precision (fp16) for faster training\n",
    "* Checkpoint saving\n",
    "* Reporting to Weights & Biases and more......\n",
    "\n",
    "You can modify the hyperparameters here to see how different settings impact model performance. Note you have an H100 (Hopper) GPU available to train, Frontier labs use this to train their models, try to make the best of it!\n",
    "\n",
    "####  üí° Create your own Fine-Tuning Strategy:\n",
    "\n",
    "üîß learning_rate  \n",
    "Controls how fast the model learns. Use 1e-4 to 2e-3; lower for full finetuning, higher for qlora.  \n",
    "Interacts with warmup_ratio and lr_scheduler_type ‚Äî higher learning rates need more warmup.\n",
    "\n",
    "‚öôÔ∏è optim  \n",
    "Selects optimizer; 'adamw_torch' is fused and faster on GPU.  \n",
    "Combine with a good learning rate and warmup for stable convergence.\n",
    "\n",
    "üìà num_train_epochs  \n",
    "Number of times the model sees the full dataset. Start low.\n",
    "Runs with more epochs will take longer and need more compute. \n",
    "\n",
    "üìä gradient_accumulation_steps  \n",
    "Simulates large batch sizes by accumulating gradients across steps.  \n",
    "We will use large batch sizes. Keep this low to speed up training.\n",
    "\n",
    "üì¶ per_device_train_batch_size  \n",
    "Controls the number of samples processed per gpu per step.  \n",
    "Larger batch = more stable gradients but more memory usage.\n",
    "Our GPU is not memory-constrained, keep this high.\n",
    "\n",
    "üî• warmup_ratio  \n",
    "Gradually ramps up learning rate to avoid early divergence.  \n",
    "Set between 0.05‚Äì0.1, especially important with higher learning rates.\n",
    "\n",
    "üìâ lr_scheduler_type  \n",
    "Controls how learning rate decays. 'cosine' gives smoother transitions, 'linear' is simpler.  \n",
    "Works in tandem with warmup_ratio and total training steps.\n",
    "\n",
    "‚ö° fp16 / bf16  \n",
    "Enables mixed-precision training for faster speed and lower memory use.  \n",
    "Use bf16 on newer GPUs (A100+, H100), fp16 works best for our A10G GPU.\n",
    "\n",
    "üß† gradient_checkpointing  \n",
    "Reduces memory by recomputing activations during backward pass.  \n",
    "Useful for large models on smaller gpus; increases compute cost.\n",
    "\n",
    "üíæ save_strategy / save_total_limit  \n",
    "Determines when and how often to save models. 'epoch' is safer for llms.  \n",
    "Limit total checkpoints (e.g., 5) to save disk space.\n",
    "\n",
    "üß™ eval_strategy  \n",
    "Controls evaluation frequency. Use 'epoch' for stability, 'steps' for faster feedback.  \n",
    "Combine with logging_steps for clear model monitoring.\n",
    "\n",
    "üìè group_by_length  \n",
    "Batches examples of similar length together.  \n",
    "Speeds up training when working with variable-length sequences.\n",
    "\n",
    "üìê auto_find_batch_size  \n",
    "Automatically adjusts batch size to prevent OOM errors.  \n",
    "\n",
    "üìù logging_steps  \n",
    "How often to log metrics like loss and learning rate.  \n",
    "Use 10‚Äì50 to balance visibility with log noise.\n",
    "\n",
    "üìä report_to  \n",
    "Set to 'wandb' to enable experiment tracking, charts, and comparisons.  \n",
    "This will ensure we can capture our training and system metrics.\n",
    "\n",
    "üèÜ metric_for_best_model  \n",
    "Automatically selects the best checkpoint based on our validation metric.  \n",
    "\n",
    "üß± weight_decay  \n",
    "Regularization to prevent overfitting. Typical values: 0.01 to 0.1.  \n",
    "Use with higher learning rates or longer training to avoid memorization.\n",
    "\n",
    "üßπ remove_unused_columns  \n",
    "Cleans up unused columns from the dataset during training.  \n",
    "\n",
    "üîÑ dataloader_num_workers / dataloader_pin_memory  \n",
    "Set workers to 4‚Äì16 for best throughput. \n",
    "\n",
    "üè∑Ô∏è label_names  \n",
    "Used to identify which label columns to include in loss computation.  \n",
    "\n",
    "*Ask our team for help if you have questions about any parameters listed here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "013c0d65",
   "metadata": {
    "editable": true,
    "id": "013c0d65",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=f\"fine-tuning-{model_name}-qlora\",\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2, #start low and go up as needed\n",
    "    per_device_train_batch_size=42,\n",
    "    per_device_eval_batch_size=4,\n",
    "    dataloader_num_workers=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    gradient_checkpointing=False, # Choose to store the full forward-pass activations in GPU RAM\n",
    "    group_by_length=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    remove_unused_columns=True,\n",
    "    dataloader_pin_memory=True,\n",
    "    optim=\"adamw_torch\", # See https://huggingface.co/docs/transformers/v4.51.3/en/perf_train_gpu_one#optimizers\n",
    "    learning_rate=2e-3,\n",
    "    lr_scheduler_type=\"cosine\", # See https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
    "    auto_find_batch_size=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_strategy=\"steps\",\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dcc2dd",
   "metadata": {
    "id": "a9dcc2dd"
   },
   "source": [
    "## üõ∞Ô∏è Engage Training Tracker\n",
    "Launch the model and track training live with W&B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faff1ee",
   "metadata": {
    "id": "7faff1ee"
   },
   "source": [
    "## üî≠ Initialize Trainer, Train, and Save üåé\n",
    "\n",
    "In this final section:\n",
    "\n",
    "* We initialize the Trainer with:\n",
    "  * The model\n",
    "  * The tokenizer\n",
    "  * The data\n",
    "  * The training arguments\n",
    "\n",
    "* We start training by calling trainer.train().\n",
    "* We save the fine-tuned adapter and tokenizer locally.\n",
    "* We finish the W&B run to close the logging cleanly. W&B has native integrations with popular training libraries! specifically here, we have a native integration with the [HF Trainer](https://docs.wandb.ai/models/integrations/huggingface)\n",
    "\n",
    "üß† Reminder: After training finishes, we will test and evaluate the fine-tuned model in this notebook.\n",
    "\n",
    "üö® Training Ahead: Be ready for longer runtimes!\n",
    "\n",
    "üî• Because you are using W&B and CoreWeave GPUs, you have deep insights in the W&B interface of CoreWeave infra issues. We don't expect to see any today, but this is highly important in inference and training workloads. [Read More Here.](https://wandb.ai/wandb_fc/product-announcements-fc/reports/New-Deep-observability-for-AI-training-and-fine-tuning-on-CoreWeave--VmlldzoxMzI1MjUwMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "050c4bfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "050c4bfd",
    "outputId": "eba166d0-e6fd-4e57-a776-0d578eb94695"
   },
   "outputs": [],
   "source": [
    "#Configure model for training\n",
    "model.config.use_cache = False  # Disable cache during training\n",
    "\n",
    "# Set label names for PEFT model\n",
    "model.config.label_names = [\"labels\"]\n",
    "\n",
    "# Initialize trainer with modified configuration\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,\n",
    "        pad_to_multiple_of=8  # Add padding to multiple of 8 for better performance\n",
    "    ),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Enable gradient checkpointing with the new format\n",
    "if hasattr(model, \"enable_input_require_grads\"):\n",
    "    model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc5c7d",
   "metadata": {
    "id": "f7bc5c7d"
   },
   "source": [
    "## ‚öô Now we kick off the training process ‚öô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93378c7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "editable": true,
    "id": "93378c7e",
    "outputId": "85122374-7278-468f-82f2-958246345a2a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/quest_notebooks/operation-reboot-aetherion-protocol/wandb/run-20251104_112759-Operation_Reboot_0324</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">Operation_Reboot_0324</a></strong> to <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 01:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.130300</td>\n",
       "      <td>2.061493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.633700</td>\n",
       "      <td>1.987093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñà‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñà‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÖ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.98709</td></tr><tr><td>eval/runtime</td><td>2.3057</td></tr><tr><td>eval/samples_per_second</td><td>69.393</td></tr><tr><td>eval/steps_per_second</td><td>17.348</td></tr><tr><td>total_flos</td><td>1.080426806378496e+16</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>70</td></tr><tr><td>train/grad_norm</td><td>0.92934</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6337</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Operation_Reboot_0324</strong> at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a><br> View project at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251104_112759-Operation_Reboot_0324/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Train\n",
    "run = wandb.init(entity=WANDB_ENTITY,\n",
    "                 project=WANDB_PROJECT_NAME,\n",
    "                 id=f\"Operation_Reboot_{timestamp}\", \n",
    "                 resume=\"allow\")\n",
    "train_output = trainer.train()\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983abf63",
   "metadata": {},
   "source": [
    "# Ensure to understand your training, and use W&B to optimize it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4c42f",
   "metadata": {
    "id": "00f4c42f"
   },
   "source": [
    "## üíæ Save & Upload\n",
    "Preserve your fine-tuned model as a W&B reference artifact in CoreWeave CAIOS storage üî•.\n",
    "\n",
    "<img src=\"https://docs.coreweave.com/assets/images/frame-87.coreweave-166308-updateallrubixcubeshapestoblack-storage-F3F3F5-Small-cb156845fe6317dcc8b3cdc56a64fba8.gif\" width=\"300\" alt=\"Falcon\" />\n",
    "\n",
    "**CoreWeave AI Object Storage** delivers exabyte-scale, S3-compatible storage tailored for GPU-intensive AI model training. Designed to integrate seamlessly with CoreWeave's NVIDIA GPU compute clusters, it supports performance levels up to 2 GB/s per GPU and scales effortlessly to hundreds of thousands of GPUs. With its unique Local Object Transport Accelerator (LOTA‚Ñ¢), AI Object Storage caches frequently used datasets and/or prestages data directly on the local NVMe disks of GPU nodes, reducing network latency and dramatically improving training speeds. [Learn more here](https://coreweave.com/products/storage#object-storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5891f1",
   "metadata": {
    "id": "1c5891f1"
   },
   "source": [
    "Tracking your model in W&B can be really helpful:\n",
    "\n",
    "- You can now share this model with your team and beyond\n",
    "- W&B creates a lineage map of your model so you can see the full model lifecycle: dataset->training->final state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f428cdbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "f428cdbc",
    "outputId": "4798665a-7613-4a82-eed3-2b67ba057f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to CAIOS: s3://fclondon2025/fc25-london-aise-likeyandy/initial_version\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/quest_notebooks/operation-reboot-aetherion-protocol/wandb/run-20251104_113141-Operation_Reboot_0324</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">Operation_Reboot_0324</a></strong> to <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Generating checksum for up to 10000000 objects in \"fclondon2025/fc25-london-aise-likeyandy/initial_version\"... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.98709</td></tr><tr><td>eval/runtime</td><td>2.3057</td></tr><tr><td>eval/samples_per_second</td><td>69.393</td></tr><tr><td>eval/steps_per_second</td><td>17.348</td></tr><tr><td>total_flos</td><td>10804268063784960</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>train/global_step</td><td>70</td></tr><tr><td>train/grad_norm</td><td>0.92934</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.6337</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Operation_Reboot_0324</strong> at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/runs/Operation_Reboot_0324</a><br> View project at: <a href='https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop' target=\"_blank\">https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop</a><br>Synced 4 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251104_113141-Operation_Reboot_0324/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Saving and uploading best model\n",
    "trainer.save_model(f\"./best_model/{type(model.base_model.model).__name__}\")\n",
    "tokenizer.save_pretrained(f\"./best_model/{type(model.base_model.model).__name__}\")\n",
    "\n",
    "###### SET A MODEL VERSION NAME SO YOU CAN REFERENCE IT LATER BEFORE SENDING TO CAIOS ###########\n",
    "VERSION_NAME=\"initial_version\"\n",
    "###### SET A MODEL VERSION NAME SO YOU CAN REFERENCE IT LATER BEFORE SENDING TO CAIOS ###########\n",
    "\n",
    "caios_path = send_to_caios(\"best_model/\", WANDB_ENTITY, VERSION_NAME)\n",
    "\n",
    "run = wandb.init(entity=WANDB_ENTITY,\n",
    "                 project=WANDB_PROJECT_NAME,\n",
    "                 id=f\"Operation_Reboot_{timestamp}\",\n",
    "                 resume=\"allow\")\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    name=f\"{WANDB_ENTITY}-ft-best-model-{type(model.base_model.model).__name__}\",\n",
    "    type=\"model\",\n",
    "    description=\"\"\"Best FineTuned model from the Astros-FT-Workshop.\"\"\"\n",
    ")\n",
    "\n",
    "artifact.add_reference(uri=caios_path)\n",
    "\n",
    "logged_artifact = run.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63b4e7-ffc6-4d91-b649-3e633e3c7771",
   "metadata": {},
   "source": [
    "### üö© Checkpoint üö© üß¨ Task 3: Artifact Uplink - Core Memory Package\n",
    "\n",
    "You've reached your second checkpoint. \n",
    "\n",
    "Navigate to wandb by clicking the link next to `View project at:` above and then click on the yellow Weights & Biases logo on the top left of the page.  \n",
    "On the left panel, click **Artifacts**. Find your artifact and retrieve the `Full Artifact Name` that you can submit on the quest page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e0cfc-63de-40a1-94ac-47fa11092cf0",
   "metadata": {},
   "source": [
    "<img src=\"imgs/artifactview.png\" alt=\"Artifact View\" style=\"max-width: 100%; width: 100%; height: auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90dd70",
   "metadata": {
    "id": "2e90dd70"
   },
   "source": [
    "## ‚úÖ Mission Checkpoint: Model Finetuned\n",
    "\n",
    "Congratulations, Architect! You've:\n",
    "- Loaded and prepped your training dataset ‚úÖ\n",
    "- Configured a foundational model ‚úÖ\n",
    "- Finetuned it with parameter-efficient methods ‚úÖ\n",
    "- Logged your training runs and saved the final model to Weights & Biases ‚úÖ\n",
    "\n",
    "Your model is now part of your mission's neural infrastructure.\n",
    "\n",
    "Next, we prepare to test and evaluate. But first, a quick system check..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e953f25",
   "metadata": {
    "id": "8e953f25"
   },
   "source": [
    "## üß∞ Systems Maintenance Bay: Utilities\n",
    "\n",
    "Before testing, it's wise to flush memory and check your hardware status. Use these utilities to prepare the environment.\n",
    "\n",
    "Just like a good engineer, make sure the ship's neural bays are cleared and ready. This will ensure our **CoreWeave GPUs** are kept nice and tidy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761f2d7",
   "metadata": {
    "id": "b761f2d7"
   },
   "source": [
    "## Utilities üß∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233f922d",
   "metadata": {
    "id": "233f922d"
   },
   "outputs": [],
   "source": [
    "# -- Flush out GPU memory - when required - may require restarting the notebook\n",
    "import gc, torch\n",
    "\n",
    "try:\n",
    "    del trainer\n",
    "except: print(\"cannot release memory\")\n",
    "try:\n",
    "    del model\n",
    "except: print(\"cannot release memory\")\n",
    "try:\n",
    "    del tokenizer\n",
    "except: print(\"cannot release memory\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a767a0d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a767a0d9",
    "outputId": "8e81b801-5015-4fbd-a287-5e0966f7e6f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  4 11:32:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |\n",
      "| N/A   30C    P0            114W /  700W |    2001MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              67      C   /opt/conda/bin/python                  1992MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f71a7",
   "metadata": {
    "id": "5d0f71a7"
   },
   "source": [
    "## üß™ Testing the Neural Core\n",
    "\n",
    "Now that your model is trained and uploaded, it‚Äôs time to test your new candidate neural core.\n",
    "\n",
    "You‚Äôll load the fine-tuned model and run test prompts to ensure it responds with precision and depth, critical for deep-space operations.\n",
    "\n",
    "We‚Äôve equipped you with a call function wrapped in `Weave`, our GenAI interface and telemetry layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60a175",
   "metadata": {
    "id": "bf60a175"
   },
   "source": [
    "## üîß Testing our model with the adapterü™õ\n",
    "\n",
    "Let's start by creating some helper functions to load and call the model we just trained.\n",
    "\n",
    "<img src=\"imgs/lora.png\" alt=\"Artifact View\" style=\"max-width: 50%; width: 50%; height: auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefdfa6c",
   "metadata": {
    "id": "eefdfa6c"
   },
   "source": [
    "Since we created an adapter during the finetuning process, our load model function loads the original model along with our adapter using PEFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8abc80",
   "metadata": {
    "id": "0e8abc80"
   },
   "source": [
    "## üõ∞Ô∏è Introducing Weave: Your AI Telemetry and Evaluation Suite\n",
    "\n",
    "<img src=\"https://mintcdn.com/wb-21fd5541/aRvhhwVWqlxBzke5/images/evals-hero.png?fit=max&auto=format&n=aRvhhwVWqlxBzke5&q=85&s=7d7466d666ad412ed3916bfab533d118\" width=\"500\" alt=\"Weave\" />\n",
    "\n",
    "[**Weave**](https://docs.wandb.ai/weave) is Weights & Biases‚Äô next-gen platform for tracking, evaluating, and visualizing GenAI applications.\n",
    "\n",
    "You'll use Weave to:\n",
    "- Log and score model generations\n",
    "- Run structured evaluations on Q&A performance\n",
    "- Compare outputs with reference answers\n",
    "\n",
    "This enables you to **quantitatively assess** how mission-ready your model is.\n",
    "\n",
    "Let‚Äôs initialize Weave and plug it into your finetuned system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "309fd38a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "309fd38a",
    "outputId": "4155a61d-a420-4e3a-e7b4-ce506a9ed1f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: likeyandy1025.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/fc25-london-aise-likeyandy/CoreWeave-Astros-FT-Workshop/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x7ad3f0619700>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "weave.init(f\"{WANDB_ENTITY}/{WANDB_PROJECT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4vH2PsqWsDD",
   "metadata": {
    "id": "F4vH2PsqWsDD"
   },
   "source": [
    "## Calling our Local Finetuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a6f0f",
   "metadata": {
    "id": "700a6f0f"
   },
   "source": [
    "### Load model\n",
    "\n",
    "We will now pass the finetuned adapter that you just trained and the base model to be loaded as one entity that we can use. You'll see the directories refferenced in the cell below are which contain the model files we are loading in. This model should be able to navigate complex astronomical questions from our evaluation dataset.\n",
    "\n",
    "These are now being loaded onto a CoreWeave state of the art GPU üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf82b834",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf82b834",
    "outputId": "5119b1d1-e3b7-47c2-ea1a-21105b2a7ca3"
   },
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': './best_model/LlamaForCausalLM'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './best_model/LlamaForCausalLM'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m base_model_dir = \u001b[33m\"\u001b[39m\u001b[33m./models/TinyLlama_v1\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Path to base model - modify accordingly to fine_tuned_model/<TinyLlama_v1 or falcon-rw-1b_v0>\u001b[39;00m\n\u001b[32m      2\u001b[39m adapter_dir = \u001b[33m\"\u001b[39m\u001b[33m./best_model/LlamaForCausalLM\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m#add path to adapter dir (FalconForCausalLM or LlamaForCausalLM)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m tokenizer, model = \u001b[43mload_finetuned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_model_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/quest_notebooks/operation-reboot-aetherion-protocol/utilities/helpers.py:371\u001b[39m, in \u001b[36mload_finetuned_model\u001b[39m\u001b[34m(adapter_dir, base_model_dir)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_finetuned_model\u001b[39m(adapter_dir, base_model_dir):\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m     \u001b[38;5;66;03m# Load model with quantization\u001b[39;00m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading model with 4-bit quantization...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1073\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m   1075\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:905\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    902\u001b[39m     token = use_auth_token\n\u001b[32m    904\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    922\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:532\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    525\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPermissionError at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m when downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCheck cache directory permissions. Common causes: 1) another user is downloading the same model (please wait); \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m2) a previous download was canceled and the lock file needs manual removal.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[32m    531\u001b[39m resolved_files = [\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[43m_get_cache_file_to_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    534\u001b[39m ]\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/hub.py:143\u001b[39m, in \u001b[36m_get_cache_file_to_return\u001b[39m\u001b[34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cache_file_to_return\u001b[39m(\n\u001b[32m    136\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    137\u001b[39m     full_filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    141\u001b[39m ):\n\u001b[32m    142\u001b[39m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     resolved_file = \u001b[43mtry_to_load_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file != _CACHED_NO_EXIST:\n\u001b[32m    147\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mzip\u001b[39m(signature.parameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[32m    103\u001b[39m     kwargs.items(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[32m    104\u001b[39m ):\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    109\u001b[39m         has_token = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:154\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRepo id must be a string, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(repo_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repo_id.count(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must be in the form \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrepo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnamespace/repo_name\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Use `repo_type` argument if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must use alphanumeric chars, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m The name cannot start or end with \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and the maximum length is 96:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './best_model/LlamaForCausalLM'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "base_model_dir = \"./models/TinyLlama_v1\" # Path to base model - modify accordingly to fine_tuned_model/<TinyLlama_v1 or falcon-rw-1b_v0>\n",
    "adapter_dir = \"./best_model/LlamaForCausalLM\" #add path to adapter dir (FalconForCausalLM or LlamaForCausalLM)\n",
    "\n",
    "tokenizer, model = load_finetuned_model(adapter_dir, base_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a6d92-b897-4894-b269-e2b7eb706605",
   "metadata": {},
   "source": [
    "#### Generating respones from the model\n",
    "\n",
    "This function acts as our interface with the model for text-based interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bb674",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "473bb674",
    "outputId": "c4eb4471-34d1-4095-f776-242bdb4231ab"
   },
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def call_model(question: str) -> str:\n",
    "    \"\"\"Generate an answer from your Local LLM given a prompt.\"\"\"\n",
    "\n",
    "    system_prompt = \"You are an expert in astrophysics. Please provide a concise and truthful answer to the following question:\"\n",
    "    prompt = system_prompt + \"\\n\\n\" + question + \"\\nAnswer:\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=256, do_sample=False, no_repeat_ngram_size=3, repetition_penalty=1.2, eos_token_id=tokenizer.eos_token_id, pad_token_id=model.config.eos_token_id)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True).replace(prompt, '').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25f02a",
   "metadata": {
    "id": "bd25f02a"
   },
   "source": [
    "## üìä Final Check: Evaluation Protocols\n",
    "\n",
    "Your neural core is active, but is it mission-grade?\n",
    "\n",
    "<img src=\"imgs/mission-grade.png\" alt=\"Artifact View\" style=\"max-width: 50%; width: 50%; height: auto;\" />\n",
    "\n",
    "Use this section to:\n",
    "- Load an evaluation dataset\n",
    "- Score model responses using embedding similarity\n",
    "- Track performance with W&B + Weave\n",
    "\n",
    "**Evaluation is critical** before deployment‚Äîit ensures your model‚Äôs reasoning is aligned with mission parameters.\n",
    "\n",
    "In this task, we will evaluate the fine-tuned models by loading them into memory and inferring locally. Once you have the evaluation results, try going back and training another model with new parameters to improve your model. Ask our team for help if you have any questions about optimizing the parameters for better results. \n",
    "\n",
    "This task carries the most points, make sure you deploy only your best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b39f03",
   "metadata": {
    "id": "a4b39f03"
   },
   "source": [
    "# Evaluating and Deployment\n",
    "\n",
    "This evaluation setup is very similar to the one used in the quest backend to score your model. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf9ddb",
   "metadata": {
    "id": "53cf9ddb"
   },
   "source": [
    "## Get Evaluation Dataset\n",
    "\n",
    "We have created a public evaluation dataset that you can use to test and quantitatively evaluate your model. This is small subset of our evalaution dataset that will be used for final scoring and should provide insights into how your finetuned model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db236752",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db236752",
    "outputId": "2123d874-4710-4544-c9bf-aa2909dab1c2"
   },
   "outputs": [],
   "source": [
    "eval_dataset_public = weave.ref('weave:///fc-london-admins/eval-dataset/object/astro_eval_public:I9rFUEYOFGJYvfbxtmL35jQkMqyitKJwf9ppYLXFQ5U').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d915b61",
   "metadata": {
    "id": "2d915b61"
   },
   "source": [
    "## Test the model with a sample from our eval dataset\n",
    "\n",
    "Let's try running our model with some sample questions from our eval dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f64721",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79f64721",
    "outputId": "71aabdb8-48ee-4498-da9e-453bacd5dbd3"
   },
   "outputs": [],
   "source": [
    "question =  random.sample(list(eval_dataset_public.rows), k=1)[0]['question'] #choose any question number between \n",
    "answer = call_model(question)\n",
    "\n",
    "print(\"üõ∞Ô∏è  Incoming Transmission ‚Äî Mission Q&A\\n\")\n",
    "print(f\"üß† Question:\\n{question}\\n\")\n",
    "print(f\"ü§ñ Model Response:\\n{answer}\")\n",
    "print(f\"ü§ñ Refernce Asnwer:\\n{eval_dataset_public[100]['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1d927",
   "metadata": {
    "id": "5bf1d927"
   },
   "source": [
    "## Setup evaluation\n",
    "\n",
    "Now that we have vibe-checked our model, let's perform a quantitative analysis of its accuracy. We will be using a simple cosine similarity scorer we've prepared in order to do binary pass/fail categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5479015",
   "metadata": {
    "id": "a5479015"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "eval_dataset = random.sample(list(eval_dataset_public.rows), k=10) # select 10-20 samples to run evaluation against"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022d08e-363e-4948-838c-3baeae93da9a",
   "metadata": {},
   "source": [
    "#### Kick off the Evaluation and view the results in Weave \n",
    "Let's see how well our model performs against our reference dataset of astronomical QnA.\n",
    "\n",
    "This evaluation takes about 5 minutes to run with 10 samples. Make sure to budget your time accordingly. \n",
    "\n",
    "Once you are satisfied with the model results, proceed to deployment. If you want to learn more about Evaluations with Weave, see [here](https://docs.wandb.ai/weave/guides/evaluation/evaluation_logger) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ef801",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "533ef801",
    "outputId": "55475355-aecc-4822-c3fc-9a085ff202e8"
   },
   "outputs": [],
   "source": [
    "evaluationlogger = weave.EvaluationLogger(\n",
    "    model=\"call_model\",\n",
    "    dataset=\"eval_dataset\",\n",
    ")\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in eval_dataset:\n",
    "    question = i[\"question\"]\n",
    "    answer = i[\"answer\"]\n",
    "\n",
    "    model_output = call_model(question)\n",
    "\n",
    "    # Log the prediction input and output\n",
    "    pred_logger = evaluationlogger.log_prediction(\n",
    "        inputs=question,\n",
    "        output=model_output\n",
    "    )\n",
    "\n",
    "    # Calculate and log a score for this prediction\n",
    "    score = cosine_similarity_scorer(model_output, question, answer)\n",
    "    scores.append(score)\n",
    "\n",
    "    pred_logger.log_score(\n",
    "        scorer=\"cosine_similarity_scorer\",\n",
    "        score=score\n",
    "    )\n",
    "\n",
    "    # Finish logging for this specific prediction\n",
    "    pred_logger.finish()\n",
    "\n",
    "avg = sum(item['similarity_score'] for item in scores) / len(scores)\n",
    "evaluationlogger.log_summary({\"cosine_similarity_scorer_avg\": avg})\n",
    "\n",
    "print(f\"Evaluation complete. Average score: {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b565f",
   "metadata": {},
   "source": [
    "Now, navigate to [Weave](https://wandb.ai/) and navigate to Evaluations to see the results of your evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f766f-cf0c-4e3d-b74a-6548846ff72e",
   "metadata": {},
   "source": [
    "## ‚öíÔ∏è Deploy üöÄ\n",
    "\n",
    "<img src=\"imgs/deploy.png\" alt=\"Artifact View\" style=\"max-width: 50%; width: 50%; height: auto;\" />\n",
    "\n",
    "#### Merge the model and the adapter\n",
    "\n",
    "We are at the end of our task. By now, you should have some freshly trained adapters for our language models that will allow us to restore functionality to our ship. Let's take your best adapter and deploy it to our ship's inference engine.\n",
    "\n",
    "Now we will merge the best adapter from our experiments to the base model and save it as once single model. All the data we trained our adapter with is now fused with the model weights. Only do this with your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the adapter weights into the base model\n",
    "model = model.merge_and_unload() # After this, it's a standard Hugging Face model\n",
    "\n",
    "config = model.config\n",
    "\n",
    "if hasattr(config, \"auto_map\"):\n",
    "    delattr(config, \"auto_map\")\n",
    "if \"auto_map\" in config.to_dict():\n",
    "    del config.__dict__[\"auto_map\"]\n",
    "\n",
    "# === Save merged model and tokenizer ===\n",
    "save_path = \"merged_model/\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Merged model saved to: {save_path}\")\n",
    "\n",
    "###### SET A MODEL VERSION NAME SO YOU CAN REFERENCE IT LATER BEFORE SENDING TO CAIOS ###########\n",
    "VERSION_NAME=\"final_submit\"\n",
    "###### SET A MODEL VERSION NAME SO YOU CAN REFERENCE IT LATER BEFORE SENDING TO CAIOS ###########\n",
    "\n",
    "## Now we upload to CoreWeave AI Object Storage for fast retrieval by CoreWeave Inference Compute for evaluations!\n",
    "caios_path = send_to_caios(\"merged_model/\", WANDB_ENTITY, VERSION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ab648-6d98-42cd-916d-72636db23c66",
   "metadata": {},
   "source": [
    "### üö© Checkpoint üö©\n",
    "\n",
    "You've reached the final checkpoint. In the output for the function above, you will have gotten a CoreWeave AI Object Storage path to the model you've submitted.\n",
    "\n",
    "\n",
    "Copy the path and enter it into the quest page to get points!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c74a4-1ef3-4d38-aa17-c849de9fa70b",
   "metadata": {},
   "source": [
    "You made it! \n",
    "\n",
    "Your ship's neural core is restored. Make sure to go back and check all the tasks marked with üö© to collect all the points.\n",
    "\n",
    "Go take a break. We will see you back here shortly for `Mission 2: Operation NAVARCH`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b048fcb50c451d89964ee93405cb93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_673061059cb64053896079a0de7d3458",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_908c81b282f64785b4fa729646b00c98",
      "value": "Map:‚Äá100%"
     }
    },
    "1173b7a21b3a4792bda7baa084fc5147": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b119211b51a4c1e847bf9c8e2fbd28c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49be6b548baf43c5bcd1091e2bfd56f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1ec82f4ca08434b85d3329bad4bf301",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ed9744b33f834485b653da828cf72026",
      "value": "‚Äá160/160‚Äá[00:00&lt;00:00,‚Äá2077.03‚Äáexamples/s]"
     }
    },
    "52c005c417a84f9aa9604239dd62197e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b119211b51a4c1e847bf9c8e2fbd28c",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ad5f99fdfdd942fab037f03f0f6c9107",
      "value": "Map:‚Äá100%"
     }
    },
    "673061059cb64053896079a0de7d3458": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c83dd832f784383aa67a7bac1c81722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02b048fcb50c451d89964ee93405cb93",
       "IPY_MODEL_f7d0f2a7a7df4589b2ff1ea0562b8ae5",
       "IPY_MODEL_ce5267e4265c49b08e066b4a5806e8cf"
      ],
      "layout": "IPY_MODEL_c7a0ffa43bfd45bb82a110520ef065c6"
     }
    },
    "6fc3ad2df4a64a2aaba0d4567e3a9277": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "908c81b282f64785b4fa729646b00c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f3f09b8e4bc411880e0d389c2043a88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad5f99fdfdd942fab037f03f0f6c9107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b45860c163b142189b6eb2eaacdcc1f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6c6c1949f1b4bbc9624647c4640dff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52c005c417a84f9aa9604239dd62197e",
       "IPY_MODEL_f5926d20d7dc4bc5a784126f57867a59",
       "IPY_MODEL_49be6b548baf43c5bcd1091e2bfd56f6"
      ],
      "layout": "IPY_MODEL_ebfc99985a16470e8e49c9b788c18302"
     }
    },
    "c7a0ffa43bfd45bb82a110520ef065c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce5267e4265c49b08e066b4a5806e8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f3f09b8e4bc411880e0d389c2043a88",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_da44f8d632714e7d89b2222686eafa5f",
      "value": "‚Äá1440/1440‚Äá[00:00&lt;00:00,‚Äá2639.12‚Äáexamples/s]"
     }
    },
    "da44f8d632714e7d89b2222686eafa5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1ec82f4ca08434b85d3329bad4bf301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebfc99985a16470e8e49c9b788c18302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed9744b33f834485b653da828cf72026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef60343739754ac7a5d61a82749f2f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5926d20d7dc4bc5a784126f57867a59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fc3ad2df4a64a2aaba0d4567e3a9277",
      "max": 160,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef60343739754ac7a5d61a82749f2f30",
      "value": 160
     }
    },
    "f7d0f2a7a7df4589b2ff1ea0562b8ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1173b7a21b3a4792bda7baa084fc5147",
      "max": 1440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b45860c163b142189b6eb2eaacdcc1f4",
      "value": 1440
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
